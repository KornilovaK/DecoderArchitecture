{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73a1f3cb-a248-4a53-9d10-96ea469623f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.serialization import safe_globals\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from src.reflex_model import GPT, Block, Attention, RMSNorm, MLP, SwiGLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c34bb728-b949-490d-9157-fdba2d884d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a737a8b-6778-46aa-ad99-23ba40627907",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cacb3d93-b480-4295-ac9d-4cccfa591e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GPTConfig:\n",
    "    batch_size: int = 8\n",
    "    block_size: int = 2048\n",
    "    vocab_size: int = 50257\n",
    "    n_layer: int = 6\n",
    "    n_head: int = 8\n",
    "    n_embd: int = 1536\n",
    "    dropout: float = 0.1\n",
    "    bias: bool = True\n",
    "    local_files_only: bool=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae519a80-8207-46f9-8e34-79be91210028",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GPTConfig()\n",
    "config.pretrained_model_path = os.path.join(main_path, 'rugpt/ckpt_4000.pt')\n",
    "config.init_type = 'load_pretrained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2db5949-e4f6-48b8-845d-0b07aea8f8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trained weights\n"
     ]
    }
   ],
   "source": [
    "allowed_classes = [GPTConfig, GPT, Block, Attention, RMSNorm, MLP, SwiGLU]    \n",
    "with safe_globals(allowed_classes):\n",
    "    model = GPT(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812d13b5-14b9-4f6a-beb0-6157e0bf886d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a15b7642-a04a-4a79-8b8f-4c11e27c888b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58e8ddc-2776-4b5f-aae8-ba5e7d98b620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "454d4eb4-ccb5-4dff-88b0-6431717d161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0.8\n",
    "max_new_tokens = 200\n",
    "top_k = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c08ba9bd-2384-4b80-8d3f-4adb667911ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    os.path.join(main_path, \"models/rugpt\"),\n",
    "    use_fast=True\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenized = tokenizer(tokenizer.bos_token)['input_ids'] + tokenizer(tokenizer.eos_token)['input_ids']\n",
    "cur_pad_token = tokenizer('#')['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60bb288-6961-4db1-916f-8b8e39fa34b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3949d6f3-1c6b-421b-885c-fb0e428f226d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03758873-4754-4eb4-b793-d86b96ba4032",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenizer.bos_token + '### Вопрос: я люблю россию. скажи, кто лучший российский писатель? ### Ответ:'\n",
    "tokens = tokenizer(text, padding='max_length', max_length=tokenizer.model_max_length)['input_ids']\n",
    "idx = torch.tensor([tokens]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f4568f3-248d-40e1-96b0-5a7d0cab7d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(idx, max_new_tokens, tokenized, cur_pad_token, temperature, top_k)\n",
    "out = tokenizer.convert_ids_to_tokens(output[0], skip_special_tokens=True)\n",
    "res = tokenizer.convert_tokens_to_string(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a636f221-667c-40f6-be85-95174a730e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Вопрос: я люблю россию. скажи, кто лучший российский писатель? ### Ответ: Кто-нибудь Я##\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a15a87-47d4-4416-b2c3-a11fe608a388",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_venv",
   "language": "python",
   "name": ".main_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
