{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c84e4470-27b0-4666-9b83-5b238e89a11b",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0cc3f9-0c2d-4e7d-bae4-19132103b9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "import wandb\n",
    "\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from reflex_model import GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dd4553-914b-4969-8363-b4cb98cced3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8479e4c9-517f-4c0f-b0ae-d5c856411a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir rugpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c4904d-19b0-4d63-b496-8bc531e08e79",
   "metadata": {},
   "source": [
    "# init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30d1d94-204b-4c4a-861d-4bb561f76ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a5eb4e-d5b5-4c74-9271-307ddee0761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GPTConfig:\n",
    "    batch_size: int = 8\n",
    "    block_size: int = 2048\n",
    "    vocab_size: int = 50257\n",
    "    n_layer: int = 6\n",
    "    n_head: int = 8\n",
    "    n_embd: int = 1536\n",
    "    dropout: float = 0.1\n",
    "    bias: bool = True\n",
    "    local_files_only: bool=True\n",
    "    \n",
    "config = GPTConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaa87c1-feb5-466f-a038-40801d733520",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.pretrained_model_path = os.path.join(main_path, \"models/rugpt\")\n",
    "config.init_type = 'init_pretrained_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb10d596-8225-4ec5-a5e6-22563e99f148",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['wandb_run_name'] = f\"KornilovaK-{params['wandb_project']}\"\n",
    "params['data_dir'] = os.path.join(main_path, \"data\")\n",
    "params['out_dir'] = os.path.join(main_path, \"rugpt\")\n",
    "params['dtype'] = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16'\n",
    "params['gradient_accumulation_steps'] = 2\n",
    "os.makedirs(params['out_dir'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f49362b-5ae8-4f08-9dea-f4b9a40b0445",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_per_iter = params['gradient_accumulation_steps'] * params['ddp_world_size'] * config.batch_size * config.block_size\n",
    "print(f\"tokens per iteration will be: {tokens_per_iter:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f22c41-7139-42cf-a496-79262beefba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.backends.cuda.flash_sdp_enabled())\n",
    "print(torch.backends.cuda.mem_efficient_sdp_enabled())\n",
    "print(torch.backends.cuda.math_sdp_enabled())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fe98c1-2878-4ac4-9620-c672443e1234",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337 + params['seed_offset'])\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "device_type = params['device']\n",
    "\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[params['dtype']]\n",
    "ctx = autocast(device_type=device_type, dtype=ptdtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101f57d4-abcb-46a9-b93b-64403fdd29a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = dict(\n",
    "    n_layer=config.n_layer,\n",
    "    n_head=config.n_head,\n",
    "    n_embd=config.n_embd,\n",
    "    block_size=config.block_size,\n",
    "    bias=config.bias,\n",
    "    vocab_size=config.vocab_size,\n",
    "    dropout=config.dropout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8beaa3d-dee9-4dd0-95c1-59a40ba2e5e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = GradScaler()\n",
    "model = GPT(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196b4229-2b1a-413b-b2c9-251475fbfe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_total = model.get_num_params()\n",
    "params_bytes = params_total*4\n",
    "params_and_buffers_bytes = params_bytes + 2*params_bytes\n",
    "print(f\"est checkpoint size: {params_and_buffers_bytes/1e9:.2f} GB\")\n",
    "print(f\"{params_total/1e6:.1f} millions of params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a493cb5-72e0-446d-bcc5-c503295bd897",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = model.configure_optimizers(params['weight_decay'], params['learning_rate'], (params['beta1'], params['beta2']), device_type)\n",
    "checkpoint = None\n",
    "\n",
    "model = torch.compile(model.to(params['device']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade4bc52-8b3f-4c1c-89ee-deaa77f37fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77ab4593-672b-4ef6-97fc-771e379f2254",
   "metadata": {},
   "source": [
    "# init run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddee2a4-4203-4079-a118-c141bacc64e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wandb.init(project=params['wandb_project'], name=params['wandb_run_name'], config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8430ca-c7b1-4998-bac3-5169f9b04ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size                    = config.block_size\n",
    "batch_size                    = config.batch_size\n",
    "data_dir                      = params['data_dir']\n",
    "learning_rate                 = params['learning_rate']\n",
    "warmup_iters                  = params['warmup_iters']\n",
    "out_dir                       = params['out_dir']\n",
    "log_interval                  = params['log_interval']\n",
    "max_iters                     = params['max_iters']\n",
    "gradient_accumulation_steps   = params['gradient_accumulation_steps']\n",
    "grad_clip                     = params['grad_clip']\n",
    "eval_interval                 = params['eval_interval']\n",
    "eval_iters                    = params['eval_iters']\n",
    "min_lr                        = params['min_lr']\n",
    "lr_decay_iters                = params['lr_decay_iters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a36ae0-0e25-42b4-b2e0-c305be2ca5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41c05db8-8609-4130-88f1-06eac70309ca",
   "metadata": {},
   "source": [
    "# run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9291b651-21f8-4f19-bb75-4afede72a7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(it):\n",
    "    if it < warmup_iters:\n",
    "        return learning_rate * it / warmup_iters\n",
    "    if it > lr_decay_iters:\n",
    "        return min_lr\n",
    "        \n",
    "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
    "    assert 0 <= decay_ratio <= 1\n",
    "    \n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))\n",
    "    return min_lr + coeff * (learning_rate - min_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fe7cec-4765-40c0-af02-68a6aca9faa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    if split == 'train':\n",
    "        data = np.memmap(os.path.join(data_dir, 'train.bin'), dtype=np.uint16, mode='r')\n",
    "    else:\n",
    "        data = np.memmap(os.path.join(data_dir, 'val.bin'), dtype=np.uint16, mode='r')\n",
    "        \n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n",
    "    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])\n",
    "    \n",
    "    assert device_type == 'cuda'\n",
    "    x, y = x.pin_memory().to(device_type, non_blocking=True), y.pin_memory().to(device_type, non_blocking=True)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e5b9d9-6f55-4875-9cf1-fcbd4d9b484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging_step(iter_num, losses, lr, running_mfu, best_val_loss):\n",
    "    print(f\"step {iter_num}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    wandb.log({\n",
    "        \"iter\": iter_num,\n",
    "        \"train/loss\": losses['train'],\n",
    "        \"val/loss\": losses['val'],\n",
    "        \"lr\": lr,\n",
    "        \"mfu\": running_mfu*100,\n",
    "    })\n",
    "\n",
    "    if losses['val'] < best_val_loss:\n",
    "        best_val_loss = losses['val']\n",
    "        if iter_num > 0:\n",
    "            checkpoint = {\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'model_args': model_args,\n",
    "                'iter_num': iter_num,\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'config': config,\n",
    "            }\n",
    "            torch.save(checkpoint, os.path.join(out_dir, f'ckpt_{iter_num}.pt'))\n",
    "\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d0e86e-1493-483b-a9ca-049548a71b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    \n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            with ctx:\n",
    "                logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "        \n",
    "    model.train()\n",
    "    \n",
    "    return out\n",
    "\n",
    "# TODO: подсчитать метрики!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dd85f3-4cb7-4d5a-b26e-3e005e4458d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(iter_num=0, best_val_loss=1e9, local_iter_num=0, running_mfu=-1.0):\n",
    "    t0 = time.time()\n",
    "    X, Y = get_batch('train')\n",
    "    \n",
    "    while True:\n",
    "        lr = get_lr(iter_num)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    \n",
    "        if iter_num % eval_interval == 0:\n",
    "            losses = estimate_loss()\n",
    "            best_val_loss = logging_step(iter_num, losses, lr, running_mfu, best_val_loss)\n",
    "                    \n",
    "        for micro_step in range(gradient_accumulation_steps):\n",
    "            with ctx:\n",
    "                logits, loss = model(X, Y)\n",
    "                loss = loss / gradient_accumulation_steps\n",
    "                \n",
    "            X, Y = get_batch('train')\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "        if grad_clip != 0.0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "    \n",
    "        t1 = time.time()\n",
    "        dt = t1 - t0\n",
    "        t0 = t1\n",
    "        if iter_num % log_interval == 0:\n",
    "            lossf = loss.item() * gradient_accumulation_steps\n",
    "            \n",
    "            if local_iter_num >= 5:\n",
    "                mfu = model.estimate_mfu(config.batch_size * gradient_accumulation_steps, dt)\n",
    "                running_mfu = mfu if running_mfu == -1.0 else 0.9*running_mfu + 0.1*mfu\n",
    "            print(f\"iter {iter_num}: loss {lossf:.4f}, time {dt*1000:.2f}ms, mfu {running_mfu*100:.2f}%\")\n",
    "            \n",
    "        iter_num += 1\n",
    "        local_iter_num += 1\n",
    "    \n",
    "        if iter_num > max_iters:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a29302-abdf-4e60-a58d-03f10706890e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea1b94c-0850-4cfc-9627-381ac22e96c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b3f1cc-5428-4601-ab2d-08a398fcc624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c21a64-c08a-49ba-b195-005bbf57ff17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4993c2a4-13c9-4dd6-8f0e-f231a7890318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7acf002-6ed9-446f-a615-f24ab934d3af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_venv",
   "language": "python",
   "name": ".main_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
